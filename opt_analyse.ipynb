{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'userName': 'Roxanne Liu', 'recievedDate': '11/08/2015', 'docID': 'ICEB-2015-0002-12058', 'comment': 'It is very enssential for America to keep the international students. They are epquiped with skills and knowledge. The development of America relies on talents. Competition should not be the reason to ask them to leave.', 'postedDate': '11/11/2015'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read(f):\n",
    "    for l in open(f):\n",
    "        yield eval(l)\n",
    "        \n",
    "x = open(\"opt_dataset/opt.json\")\n",
    "i = 0\n",
    "training = open(\"opt_dataset/small_opt.json\",'w')\n",
    "\n",
    "for l in x:\n",
    "    if (i>=0) and (i<5000):\n",
    "        training.write(l)\n",
    "        if(i==0):\n",
    "            print l\n",
    "    i += 1\n",
    "training.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "\n",
    "comments = []\n",
    "usernames = []\n",
    "count = 0\n",
    "for i in read('opt_dataset/small_opt.json'):\n",
    "    comments.append(i['comment'])\n",
    "    usernames.append(i['userName'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in comments:\n",
    "    r = ''.join([c for c in i.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        # w = stemmer.stem(w)\n",
    "        wordCount[w] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "from sets import Set\n",
    "vocab = Set()\n",
    "for i in range(600):\n",
    "    r = ''.join([c for c in comments[i].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        vocab.add(w)\n",
    "numberpos = 0\n",
    "numberneg = 0\n",
    "for l in open('opt_dataset/labels_1-700.txt'):\n",
    "    if(eval(l) == 1):\n",
    "        labels.append(1)\n",
    "        numberpos += 1\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        numberneg += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implementing bernoulli Naive Bayes. Another popular version is multinomial naive bayes\n",
    "pos_wordCount = defaultdict(int)\n",
    "neg_wordCount = defaultdict(int)\n",
    "for w in vocab:\n",
    "    pos_wordCount[w] = 0\n",
    "    neg_wordCount[w] = 0\n",
    "# calculating the probabilites\n",
    "for i in range(450):\n",
    "    r = ''.join([c for c in comments[i].lower() if not c in punctuation])\n",
    "    bag = r.split()\n",
    "    for w in vocab:\n",
    "        if w in bag:\n",
    "            if(labels[i] == 1):\n",
    "                pos_wordCount[w] += 1\n",
    "            else:\n",
    "                neg_wordCount[w] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalizing, with some kind of smoothing\n",
    "\n",
    "pos_wordprob = defaultdict(float)\n",
    "neg_wordprob = defaultdict(float)\n",
    "\n",
    "for w in vocab:\n",
    "    pos_wordprob[w] = 1.0*(pos_wordCount[w] + 0.01)/(1 + numberpos)\n",
    "    neg_wordprob[w] = 1.0*(neg_wordCount[w] + 0.01)/(1 + numberneg)\n",
    "posprob = numberpos*1.0/(numberpos+numberneg)\n",
    "negprob = numberneg*1.0/(numberpos+numberneg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def predpos(words):\n",
    "    sum = 0.0\n",
    "    for w in vocab:\n",
    "        if(w in words):\n",
    "            sum += math.log(pos_wordprob[w])\n",
    "        else:\n",
    "            sum += math.log(1-pos_wordprob[w])\n",
    "    return math.log(posprob) + sum\n",
    "            \n",
    "def predneg(words):\n",
    "    sum = 0.0\n",
    "    for w in vocab:\n",
    "        if(w in words):\n",
    "            sum += math.log(neg_wordprob[w])\n",
    "        else:\n",
    "            sum += math.log(1-neg_wordprob[w])\n",
    "    return math.log(negprob) + sum\n",
    "            \n",
    "predictions = []            \n",
    "for i in range(450):\n",
    "    r = ''.join([c for c in comments[i].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    if(predpos(words) > predneg(words)):\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-69-e8f66a691ae8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-69-e8f66a691ae8>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    xprint i,comments[i], \"predicted: \", predictions[i], \"Actual:\", labels[i],\"\\n\"\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(450):\n",
    "    if(predictions[i] != labels[i]):\n",
    "        print i,comments[i], \"predicted: \", predictions[i], \"Actual:\", labels[i],\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multinomial naive bayes!\n",
    "\n",
    "pos_wordCount_mult = defaultdict(int)\n",
    "neg_wordCount_mult = defaultdict(int)\n",
    "for w in vocab:\n",
    "    pos_wordCount_mult[w] = 0\n",
    "    neg_wordCount_mult[w] = 0\n",
    "numberpos_mult = 0\n",
    "numberneg_mult = 0\n",
    "# calculating the probabilites\n",
    "for i in range(600):\n",
    "    r = ''.join([c for c in comments[i].lower() if not c in punctuation])\n",
    "    bag = r.split()\n",
    "    for w in bag:\n",
    "        if(labels[i] == 1):\n",
    "            pos_wordCount_mult[w] += 1\n",
    "            numberpos_mult += 1\n",
    "        else:\n",
    "                neg_wordCount_mult[w] += 1\n",
    "                numberneg_mult += 1\n",
    "                \n",
    "pos_wordprob_mult = defaultdict(float)\n",
    "neg_wordprob_mult = defaultdict(float)\n",
    "\n",
    "for w in vocab:\n",
    "    pos_wordprob_mult[w] = 1.0*(pos_wordCount_mult[w] + 1)/(len(vocab) + numberpos_mult)\n",
    "    neg_wordprob_mult[w] = 1.0*(neg_wordCount_mult[w] + 1)/(len(vocab) + numberneg_mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def predpos_mult(words):\n",
    "    sum = 0.0\n",
    "    for w in words:\n",
    "        if(w in vocab):\n",
    "            sum += math.log(pos_wordprob_mult[w])\n",
    "    return (math.log(posprob) + sum)\n",
    "            \n",
    "def predneg_mult(words):\n",
    "    sum = 0.0\n",
    "    for w in words:\n",
    "        if(w in vocab):\n",
    "            sum += math.log(neg_wordprob_mult[w])\n",
    "    return (math.log(negprob) + sum)\n",
    "            \n",
    "predictions_mult = []\n",
    "LLP = []\n",
    "LLN = []\n",
    "for i in range(len(comments)):\n",
    "    r = ''.join([c for c in comments[i].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    x = predpos_mult(words)\n",
    "    y = predneg_mult(words)\n",
    "    LLP.append(x)\n",
    "    LLN.append(y)\n",
    "    if(x > y):\n",
    "        predictions_mult.append(1)\n",
    "    else:\n",
    "        predictions_mult.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n"
     ]
    }
   ],
   "source": [
    "# Semi supervised learning, Some kind of expectation maximization...\n",
    "num_iter = 0\n",
    "while(num_iter < 4):\n",
    "    pos_wordCount_mult = defaultdict(int)\n",
    "    neg_wordCount_mult = defaultdict(int)\n",
    "    for w in vocab:\n",
    "        pos_wordCount_mult[w] = 0\n",
    "        neg_wordCount_mult[w] = 0\n",
    "    numberpos_mult = 0\n",
    "    numberneg_mult = 0\n",
    "    # calculating the probabilites\n",
    "    for i in range(len(comments)):\n",
    "        r = ''.join([c for c in comments[i].lower() if not c in punctuation])\n",
    "        bag = r.split()\n",
    "        for w in bag:\n",
    "            if(predictions_mult[i] == 1):\n",
    "                pos_wordCount_mult[w] += 1\n",
    "                numberpos_mult += 1\n",
    "            else:\n",
    "                    neg_wordCount_mult[w] += 1\n",
    "                    numberneg_mult += 1\n",
    "\n",
    "    pos_wordprob_mult = defaultdict(float)\n",
    "    neg_wordprob_mult = defaultdict(float)\n",
    "\n",
    "    for w in vocab:\n",
    "        pos_wordprob_mult[w] = 1.0*(pos_wordCount_mult[w] + 1)/(len(vocab) + numberpos_mult)\n",
    "        neg_wordprob_mult[w] = 1.0*(neg_wordCount_mult[w] + 1)/(len(vocab) + numberneg_mult)\n",
    "\n",
    "    predictions_mult = []\n",
    "    LLP = []\n",
    "    LLN = []\n",
    "    for i in range(len(comments)):\n",
    "        r = ''.join([c for c in comments[i].lower() if not c in punctuation])\n",
    "        words = r.split()\n",
    "        x = predpos_mult(words)\n",
    "        y = predneg_mult(words)\n",
    "        LLP.append(x)\n",
    "        LLN.append(y)\n",
    "        if(x > y):\n",
    "            predictions_mult.append(1)\n",
    "        else:\n",
    "            predictions_mult.append(0)\n",
    "    \n",
    "    num_iter += 1\n",
    "    print \"iteration number:\",num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POTUS...just why are you selling us out at every opportunity? TPP...UN...Corporate power...runaway immigration...Zionist Israel...just for starters...The New World Order is NOT fantasy....Just stop your bushwhacking Fascism! How about training Americans who need it? True label: 0 Predicted label: 1\n",
      "I see absolutely no reason for expanding the opportunities F-1 nonimmigrant students who merely make it much harder for United States young people who have such a difficult time finding work. Please do not allow additional visas or additional time for F-1 individuals to work in the U.S. True label: 0 Predicted label: 1\n",
      "Enough is Enough. What ever happened to WE THE PEOPLE? True label: 0 Predicted label: 1\n",
      "This is too much and redirects efforts away form our Country's educational system. The First priority should be to make sure we can not fill the STEM jobs with applicants within the Fifty State and Graduates within our boarders. I think this bill does not do enough for our citizens First and only certain jobs will require those trained abroad. I think this bill does not do enough to identify the specific Jobs that are not able to be filled here at home. This is too much and redirects efforts away from our Country's educational system. True label: 0 Predicted label: 1\n",
      "When we have over 94,000 Americans unemployed because they can't find a job, why are we intentionally bringing in immigrants to fill those jobs? That is our problem, we bring in immigrants to fill jobs that Americans aren't offered, even though they are already qualified. No, businesses would rather hire untrained employees and teach them enough to get the job done and no more, and at a substantial reduction in wages. When are we going to wake up to the problem that allowing millions of immigrants into our country, keeps thousands of Americans unemployed. That is unacceptable. This country needs to put it's citizens first. No more giving entitlements to those who have not invested anything in this country. If people want to emigrate here they need to become Americans first, not hyphenated Americans. When you come here to become a citizen, you give up your old country, not just in name, but also in culture. Don't try to bring your culture to this country and expect your countries culture to be accepted here. Assimilate, become part of the melting pot that America is, learn English and our culture. If you left a country because you were persecuted, why would you want to bring that with you to a new country. You came here to change you life, so change, don't go back to what you had, overthrow that old lifestyle and accept freedom. True label: 0 Predicted label: 1\n",
      "US workers don't have jobs. We have record unemployment. We don't need any more foreign workers until our own people are taken care of. Our own STEM students have burdensome student loans and they need work when they graduate. The promises to them have been broken. True label: 0 Predicted label: 1\n",
      "I am still confused as to why our own government, or as I see it now ,our controllers, continue to push for foreign worker training (OPT) rather than using the same training from our citizens. It reminds me of the cell phone services, once they get you to sign up there's no loyalty. I can only think in this case it'as all about the money. Our employers can save cost on pay based on foreign worker complement. I believe there is a current law to eliminate the hiring of foreign worker if citizen workers are available. I also understand that if an employer is caught cheating on this law he his permanently barred from further participation in this practice, So I guess the problem again is the government no doing it's job, of course it will be blamed on the lack of funds to properly execute this action of oversight. I suggest we first look at the agency assigned to oversee this.issue and see what kind of production we get from the people working at this agency. I suspect you will find we only get about one to two hours for an eight hour day. There in lie the problem with our government and that due to federal unions, workers are protected way beyond their usefulness. We pretty much know that in the private sector this would not be tolerated and firings, layoffs and what other methods necessary for increase in production would be effected. True label: 0 Predicted label: 1\n",
      "Please allow current non-immigrant students studying STEM or recent graduates to compete for jobs. There are enough talented workers looking for jobs. Please do not allow immigrants to take these jobs away from them. True label: 0 Predicted label: 1\n",
      "A. Purpose of the Regulatory Action  This proposed rule is open to literally every foreign person in the world regardless of the ability to succeed at a U.S. school thus, the regulation does not seek bright students. The F1 nonimmigrant classification is available to certain academic students seeking temporary admission to the United States as full-time students at an established college, university, seminary, conservatory, academic high school, elementary school, or other academic institution or in an accredited language training program. In short, every and any school is a qualifying school. Thus, by definition, any foreigner who wants to come to the U.S. to attend elementary school qualifies under this regulation. The 911 terrorist would have qualified under this broad definition.  OPT is a form of temporary employment lasting 48 months,which is nobody's definition of temporary. Since the whole college experience begins and ends in 48 months, then the OPT program is a school unto itself 48 months is the course of study. A student can apply to engage in OPT during their academic program, known as pre-completion OPT, As admitted in this Regulation and in the Immigration Code this regulation assists the foreign student to change status to H1B thus eligible to replace a qualified US worker WITHOUT A DEGREE OR EXPERIENCE. or after completing the academic program, known as post-completion OPT. As admitted in the first sentence OPT is a form of employment. Clearly, the regulation is NOT meant for educational purposes but is in the end an employment program for and only for foreign students. {NOTE: U.S. STUDENTS ARE EXCLUDED FROM THIS PRIVILEGED PROGRAM.} True label: 0 Predicted label: 1\n",
      "As a US citizen, I personally think OPT program abuse is too prevailing to be acceptable for US public. However, I do believe there should be common ground as US should retain talented foreign students while preventing abuse Therefore I suggest the new OPT rule should be improved by these steps:  1) very clear and high enough prevailing wage requirement for employers to recruit students on OPT. 2) set up a black list of companies that abuse OPT and H1b, those in black list will be forever barred from using OPT or H1b program. 3)OPT program should only be available for students from top 50-100 US universities, the current provision \"accredited Universities\" is too vague. I also suggest Chinese students to comment about how to improve the OPT extension as above, in this case, you can at least win support from relatively reasonable people like me True label: 0 Predicted label: 1\n",
      "The Optional Practical Training program allows U.S. employers to hire foreign students for up to 1 year or up to 29 months in certain fields of study. The program was meant to provide foreign students with on-the-job training that would benefit them when they return to their home countries. Instead, this proposed rule, which will extend the program for STEM students to 36 months, would create a bridge to a longer-term work visa and eventual green card. This is a direct violation of the foreign student's pledge when they received their student visa to leave the country upon graduation. It's hard enough already for American workers, especially recent U.S. graduates, to find work, and this rule would make it even more difficult by adding unnecessary job competition to the mix. How does this help American workers, when people such as Gates, Zuckenberg and the like continue to promote the hiring of these \"students\" with more added benefits than our own . This must stop, if our Representatives, Senators and Congressmen continue to disregard the needs of the people they represent, whom will they turn to or what is worse what actions will they turn to when those in power seem to play a blind eye to their requests? May that not be the outcome to our future. True label: 0 Predicted label: 1\n",
      "Perhaps we should think of the American students and workers first, rather than trying to allow this proposed rule to be enacted. I was an engineering student quite a few years ago and after graduation I was offered a job overseas I had to go through a vetting process and was then placed onto a list of potential employees for this company. I had a ninety day waiting period during which time the company was required to make any and every effort to hire a citizen of that country before I could be employed by them. Guess what? I never did get a chance to work there because they filled the position with a citizen of that country. The United States should follow the same rules and regulations for foreign nationals as the most stringent of the other countries with whom we deal. We also should not be giving foreign nationals student loans, scholarships, student work programs or any other educational assistance until all other U. S. candidates have been taken care of 100%. Do not allow this proposed rule to become enacted! True label: 0 Predicted label: 1\n",
      "This extension of time for foreign STEM workers to be employed goes way beyond the \"training\" period. It sets up an unfair competitive advantage over American tech workers trying to enter the workplace. The student spaces should be used to train Americans. The lower wages do nothing but provide extra profits for tech companies that already are making a fortune ripping off American consumers. The \"shortage\" of tech workers is a scam; plenty of Americans need work, the industry just doesn't want to pay fair wages! The lack of paying payroll/social security taxes is inexcusable! Americans should be given jobs and taxes should be paid. The whole program should be shut down, not just the extension! This is politics at its worst, no wonder the tech area gives so much money to politicians! These foreign students need to go home after graduation and help build the economies of their own countries instead of having them continue to fall behind and require US economic assistance.  This F-1 rule proposal deserves a BIG F- grade on all counts! True label: 0 Predicted label: 1\n",
      "I would like to lodge my opposition to increasing amounts of F1 students and the offering of local jobs to them. I myself am a tech worker and it is getting harder to get any sort of raise or increase in standard of living. True label: 0 Predicted label: 1\n",
      "Test accuracy: 0.86 Train accuracy: 0.976666666667\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = 0.0\n",
    "test_accuracy = 0.0\n",
    "for i in range(700):\n",
    "    if(predictions_mult[i] == labels[i]):\n",
    "        if i<600:\n",
    "            train_accuracy += 1\n",
    "        else:\n",
    "            test_accuracy += 1\n",
    "    elif(i>=600  and i<700):\n",
    "        print comments[i], \"True label:\",labels[i],\"Predicted label:\",predictions_mult[i]\n",
    "print \"Test accuracy:\",test_accuracy/100,\"Train accuracy:\", train_accuracy/600 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
